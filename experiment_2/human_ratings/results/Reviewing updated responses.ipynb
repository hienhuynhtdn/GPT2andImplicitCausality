{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f0ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f4f86",
   "metadata": {},
   "source": [
    "## Define core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a719f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://stackoverflow.com/a/312464\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "def get_answers(entry):\n",
    "    \"\"\"\n",
    "    Just get the plain answers without anything else.\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for prompt in prompts:\n",
    "        answer = entry[prompt]\n",
    "        if answer:\n",
    "            answers.append(answer)\n",
    "    return answers\n",
    "\n",
    "\n",
    "def get_answer_dict(entry):\n",
    "    \"\"\"\n",
    "    Get the answered prompts with answers.\n",
    "    \"\"\"\n",
    "    answers = dict()\n",
    "    for prompt in prompts:\n",
    "        answer = entry[prompt]\n",
    "        if answer:\n",
    "            answers[prompt] = answer\n",
    "    return answers\n",
    "\n",
    "\n",
    "likert_map = {'Strongly disagree': 0,\n",
    "              'Somewhat disagree': 1,\n",
    "              'Neither agree nor disagree': 2,\n",
    "              'Somewhat agree': 3,\n",
    "              'Strongly agree': 4}\n",
    "\n",
    "\n",
    "def map_to_numbers(values):\n",
    "    \"\"\"\n",
    "    Map list of responses to numerical values\n",
    "    \"\"\"\n",
    "    return [likert_map[v] for v in values]\n",
    "\n",
    "\n",
    "def answers_to_numbers(d):\n",
    "    \"\"\"\n",
    "    Generate list of numbers based on dict of answers.\n",
    "    \"\"\"\n",
    "    answers = [d[k] for k in sorted(d.keys())]\n",
    "    return map_to_numbers(answers)\n",
    "               \n",
    "\n",
    "def average_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Average values for a list of lists.\n",
    "    \"\"\"\n",
    "    return [sum(pair)/len(pair) for pair in zip(*list_of_lists)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4aa988",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the data and select those responses where we have obtained informed consent, and who answered all 40 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ddb26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be 80 (our total number of participants): 80\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warning from openpyxl that the workbook contains no default style:\n",
    "with warnings.catch_warnings(record=True):\n",
    "    df = pd.read_excel(\"Qualtrics-round2.xlsx\", na_filter=False)\n",
    "\n",
    "df = df[df['Status'] != \"Survey Preview\"]\n",
    "\n",
    "prompts = [label for label in df.columns if label.isdigit()]\n",
    "blocks = {' '.join(sorted(chunk)): i for i, chunk in enumerate(chunks(prompts, 40), start=1)}\n",
    "\n",
    "with_consent = df[df['Q1002']=='Yes']\n",
    "responses = with_consent.to_dict('records')\n",
    "responses = [r for r in responses if len(get_answers(r)) == 40]\n",
    "\n",
    "print(\"This should be 80 (our total number of participants):\", len(responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3972b32",
   "metadata": {},
   "source": [
    "## Group participants\n",
    "\n",
    "Group participants by the questions they answered. Recall that each participant only answered 40 questions, out of 1000. In the next step we want to compare participants who answered the same questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67142ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = defaultdict(list)\n",
    "for response in responses:\n",
    "    answers = get_answer_dict(response)\n",
    "    key = ' '.join(sorted(answers.keys()))\n",
    "    grouped[key].append((response['PROLIFIC_PID'], answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56f516",
   "metadata": {},
   "source": [
    "## Select updated blocks\n",
    "\n",
    "First look at the updated block to see if correlations improved. We collected:\n",
    "* Two more responses for block 5\n",
    "* One more response for block 17\n",
    "* Two more responses for block 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29bf232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: '11 113 154 168 197 199 23 233 242 25 276 289 299 336 362 393 417 444 481 543 570 594 628 655 67 673 697 698 709 726 730 734 762 77 811 814 89 913 916 988',\n",
       " 17: '136 138 160 170 173 218 240 274 288 333 335 346 347 348 376 41 411 439 545 547 560 576 626 66 740 748 778 783 809 86 890 898 908 922 940 959 968 970 98 986',\n",
       " 23: '110 167 177 194 248 290 310 35 375 383 402 413 424 449 491 511 512 517 519 520 561 601 603 679 680 686 690 719 728 755 761 794 797 816 849 866 873 88 903 952'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{block: prompts for prompts,block in blocks.items() if block in [5,17,23]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf003c",
   "metadata": {},
   "source": [
    "## Compare participants\n",
    "\n",
    "We again use a leave-one-out strategy to compare each participant with the average scores of the other participants who answered the same question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cf479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for block 17:\n",
      "Score for 5e9d59e26627630009d1f013 is: 0.348955064468428\n",
      "Score for 62a8375ef5d3cb6960e4ed2e is: 0.6017170744243113\n",
      "Score for 5f5a292573b827085d758463 is: 0.6150521180597369\n",
      "Score for 5e8e0592039e71067ee874a5 is: 0.7066257113774909\n",
      "Results for block 23:\n",
      "Score for 60d2295bcb7135a034690583 is: -0.11146199789072132\n",
      "Score for 5b5eda691900510001e970b3 is: 0.3151651477365368\n",
      "Score for 60eec4cb6baff7af36bc4c45 is: 0.49385179175410276\n",
      "Score for 62926f5a375553f13d68bc92 is: 0.5112887731612005\n",
      "Score for 6100af50f41049317edf4099 is: 0.6398311136865183\n",
      "Results for block 5:\n",
      "Score for 614e31ad5927c89cb387915d is: 0.13529577644610655\n",
      "Score for 5f60a29da41c6f05389423b5 is: 0.6272686329531223\n",
      "Score for 5c4b987538878c0001c7883b is: 0.6745976324154203\n",
      "Score for 5f8bb4f68cb05a2f5c15130a is: 0.6764845576375023\n",
      "Score for 5c982494dd325800146f870e is: 0.7512766297970671\n"
     ]
    }
   ],
   "source": [
    "corr_per_block = defaultdict(list)\n",
    "\n",
    "for group in grouped.values():\n",
    "    # Indices corresponds to the indices for each participant.\n",
    "    indices = set(range(len(group)))\n",
    "    # This for-loop looks at each participant in turn.\n",
    "    for i in range(len(group)):\n",
    "        # Select participant with index i.\n",
    "        selected_id, selected_answers = group[i]\n",
    "        block = blocks[' '.join(sorted(selected_answers.keys()))]\n",
    "\n",
    "        # only run code for selected blocks:\n",
    "        if block in {5,17,23}:\n",
    "            selected_values = answers_to_numbers(selected_answers)\n",
    "\n",
    "            # Others are the complement of that:\n",
    "            others = [answers_to_numbers(group[x][1]) for x in (indices - {i})]\n",
    "            avg_others = average_lists(others)\n",
    "\n",
    "            # Compute Spearman correlation between the selected participant and the others.\n",
    "            corr, pvalue = spearmanr(selected_values, avg_others)\n",
    "            \n",
    "            # Store results\n",
    "            corr_per_block[block].append((corr, selected_id))\n",
    "\n",
    "for block, results in corr_per_block.items():\n",
    "    print(f\"Results for block {block}:\")\n",
    "    for corr, participant in sorted(results):\n",
    "        print(f\"Score for {participant} is: {corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054b9b9",
   "metadata": {},
   "source": [
    "**Observation:** two participants really stand out:\n",
    "* `60d2295bcb7135a034690583` with a negative correlation.\n",
    "* `614e31ad5927c89cb387915d` with a very low correlation of 0.135.\n",
    "\n",
    "What are their answers like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4505d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers for participant 614e31ad5927c89cb387915d:\n",
      "Counter({'Neither agree nor disagree': 14, 'Somewhat disagree': 13, 'Strongly disagree': 7, 'Somewhat agree': 4, 'Strongly agree': 2})\n",
      "\n",
      "Answers for participant 60d2295bcb7135a034690583:\n",
      "Counter({'Neither agree nor disagree': 39, 'Somewhat agree': 1})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = set()\n",
    "for block, results in corr_per_block.items():\n",
    "    for corr, participant in results:\n",
    "        if corr < 0.15:\n",
    "            outliers.add(participant)\n",
    "\n",
    "for response in responses:\n",
    "    identifier = response['PROLIFIC_PID']\n",
    "    if identifier in outliers:\n",
    "        answers = get_answer_dict(response)\n",
    "        print(f\"Answers for participant {identifier}:\")\n",
    "        print(Counter(answers.values()))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aec5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded outliers:\n",
      "5e9d59e26627630009d1f013\n",
      "5b5eda691900510001e970b3\n",
      "60d2295bcb7135a034690583\n",
      "5f60a29da41c6f05389423b5\n",
      "614e31ad5927c89cb387915d\n"
     ]
    }
   ],
   "source": [
    "# Let's define outliers again, so that we select the three best responses:\n",
    "outliers = []\n",
    "for block, results in corr_per_block.items():\n",
    "    sorted_scores = sorted(results, reverse=True)\n",
    "    leftover = [participant for corr, participant in sorted_scores[3:]]\n",
    "    outliers.extend(leftover)\n",
    "\n",
    "print(\"Excluded outliers:\")\n",
    "for outlier in outliers:\n",
    "    print(outlier)\n",
    "\n",
    "responses_for_analysis = [r for r in responses if not r[\"PROLIFIC_PID\"] in outliers]\n",
    "df = pd.DataFrame(responses_for_analysis)\n",
    "df.to_excel(\"Selected_for_analysis.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b109d",
   "metadata": {},
   "source": [
    "## Comparing, again\n",
    "\n",
    "Let's compare the participants again, without the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84673afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = defaultdict(list)\n",
    "for response in responses:\n",
    "    answers = get_answer_dict(response)\n",
    "    key = ' '.join(sorted(answers.keys()))\n",
    "    identifier = response['PROLIFIC_PID']\n",
    "    if not identifier in outliers:\n",
    "        grouped[key].append((identifier, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355792c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for block 23:\n",
      "Score for 62926f5a375553f13d68bc92 is: 0.4827382302572014\n",
      "Score for 60eec4cb6baff7af36bc4c45 is: 0.5647026851639074\n",
      "Score for 6100af50f41049317edf4099 is: 0.607219512214692\n",
      "Results for block 5:\n",
      "Score for 5c4b987538878c0001c7883b is: 0.6872742703094431\n",
      "Score for 5c982494dd325800146f870e is: 0.6939449149164243\n",
      "Score for 5f8bb4f68cb05a2f5c15130a is: 0.7447242954260107\n",
      "Results for block 17:\n",
      "Score for 5f5a292573b827085d758463 is: 0.6557561485739504\n",
      "Score for 5e8e0592039e71067ee874a5 is: 0.6686957367267742\n",
      "Score for 62a8375ef5d3cb6960e4ed2e is: 0.6849337909794981\n"
     ]
    }
   ],
   "source": [
    "corr_per_block = defaultdict(list)\n",
    "\n",
    "for group in grouped.values():\n",
    "    # Indices corresponds to the indices for each participant.\n",
    "    indices = set(range(len(group)))\n",
    "    # This for-loop looks at each participant in turn.\n",
    "    for i in range(len(group)):\n",
    "        # Select participant with index i.\n",
    "        selected_id, selected_answers = group[i]\n",
    "        block = blocks[' '.join(sorted(selected_answers.keys()))]\n",
    "\n",
    "        # only run code for selected blocks:\n",
    "        if block in {5,17,23}:\n",
    "            selected_values = answers_to_numbers(selected_answers)\n",
    "\n",
    "            # Others are the complement of that:\n",
    "            others = [answers_to_numbers(group[x][1]) for x in (indices - {i})]\n",
    "            avg_others = average_lists(others)\n",
    "\n",
    "            # Compute Spearman correlation between the selected participant and the others.\n",
    "            corr, pvalue = spearmanr(selected_values, avg_others)\n",
    "            \n",
    "            # Store results\n",
    "            corr_per_block[block].append((corr, selected_id))\n",
    "\n",
    "for block, results in corr_per_block.items():\n",
    "    print(f\"Results for block {block}:\")\n",
    "    for corr, participant in sorted(results):\n",
    "        print(f\"Score for {participant} is: {corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae6e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
